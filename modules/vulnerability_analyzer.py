import boto3
import json
import os
from typing import Dict, List, Any
from datetime import datetime

class VulnerabilityAnalyzer:
    def __init__(self, aws_clients):
        self.bedrock = aws_clients['bedrock-runtime']
        self.available_models = self._get_available_models()
    
    def _get_available_models(self) -> List[str]:
        """Get available Bedrock models"""
        try:
            # Try to get available models (you might need to request access first)
            models = [
                "anthropic.claude-3-sonnet-20240229-v1:0",
                "anthropic.claude-3-haiku-20240307-v1:0",
                "anthropic.claude-v2",
                "amazon.titan-text-express-v1",
                "ai21.j2-ultra-v1"
            ]
            return models
        except Exception as e:
            print(f"Warning: Could not list Bedrock models: {e}")
            return ["anthropic.claude-3-sonnet-20240229-v1:0"]  # Fallback
    
    def analyze_vulnerability(self, vulnerability: Dict, resource_context: Dict) -> Dict:
        """Use AWS Bedrock to analyze vulnerability and suggest remediation"""
        
        prompt = self._create_analysis_prompt(vulnerability, resource_context)
        
        try:
            # Try Claude 3 first, fallback to other models
            model_id = self.available_models[0]
            
            if "claude-3" in model_id:
                return self._invoke_claude_3(model_id, prompt, vulnerability)
            elif "claude" in model_id:
                return self._invoke_claude_v2(model_id, prompt, vulnerability)
            elif "titan" in model_id:
                return self._invoke_titan(model_id, prompt, vulnerability)
            elif "j2" in model_id:
                return self._invoke_jurassic2(model_id, prompt, vulnerability)
            else:
                return self._get_fallback_remediation(vulnerability)
                
        except Exception as e:
            print(f"Bedrock invocation failed: {e}")
            return self._get_fallback_remediation(vulnerability)
    
    def _invoke_claude_3(self, model_id: str, prompt: str, vulnerability: Dict) -> Dict:
        """Invoke Claude 3 model"""
        body = {
            "anthropic_version": "bedrock-2023-05-31",
            "max_tokens": 1000,
            "temperature": 0.1,
            "messages": [
                {
                    "role": "user",
                    "content": prompt
                }
            ]
        }
        
        response = self.bedrock.invoke_model(
            modelId=model_id,
            body=json.dumps(body)
        )
        
        response_body = json.loads(response['body'].read())
        analysis = response_body['content'][0]['text']
        return self._parse_ai_response(analysis, vulnerability)
    
    def _invoke_claude_v2(self, model_id: str, prompt: str, vulnerability: Dict) -> Dict:
        """Invoke Claude V2 model"""
        body = {
            "prompt": f"\n\nHuman: {prompt}\n\nAssistant:",
            "max_tokens_to_sample": 1000,
            "temperature": 0.1,
            "top_p": 0.9,
        }
        
        response = self.bedrock.invoke_model(
            modelId=model_id,
            body=json.dumps(body)
        )
        
        response_body = json.loads(response['body'].read())
        analysis = response_body['completion']
        return self._parse_ai_response(analysis, vulnerability)
    
    def _invoke_titan(self, model_id: str, prompt: str, vulnerability: Dict) -> Dict:
        """Invoke Amazon Titan model"""
        body = {
            "inputText": prompt,
            "textGenerationConfig": {
                "maxTokenCount": 1000,
                "temperature": 0.1,
                "topP": 0.9
            }
        }
        
        response = self.bedrock.invoke_model(
            modelId=model_id,
            body=json.dumps(body)
        )
        
        response_body = json.loads(response['body'].read())
        analysis = response_body['results'][0]['outputText']
        return self._parse_ai_response(analysis, vulnerability)
    
    def _invoke_jurassic2(self, model_id: str, prompt: str, vulnerability: Dict) -> Dict:
        """Invoke AI21 Jurassic-2 model"""
        body = {
            "prompt": prompt,
            "maxTokens": 1000,
            "temperature": 0.1,
            "topP": 0.9,
        }
        
        response = self.bedrock.invoke_model(
            modelId=model_id,
            body=json.dumps(body)
        )
        
        response_body = json.loads(response['body'].read())
        analysis = response_body['completions'][0]['data']['text']
        return self._parse_ai_response(analysis, vulnerability)
    
    def _create_analysis_prompt(self, vulnerability: Dict, resource_context: Dict) -> str:
        """Create AI prompt for vulnerability analysis"""
        
        return f"""
        You are a cloud security expert specializing in AWS security remediation. 
        Analyze this AWS security vulnerability and provide detailed remediation steps.

        VULNERABILITY:
        - ID: {vulnerability.get('id', 'Unknown')}
        - Title: {vulnerability.get('title', 'Unknown')}
        - Severity: {vulnerability.get('severity', 'Unknown')}
        - Description: {vulnerability.get('description', 'No description')}
        
        RESOURCE CONTEXT:
        - Type: {resource_context.get('resource_type', 'Unknown')}
        - ID: {resource_context.get('resource_id', 'Unknown')}
        - Additional Info: {json.dumps(resource_context, indent=2)}
        
        Please provide a structured analysis with:
        1. Risk assessment (1-2 sentences)
        2. Step-by-step remediation instructions
        3. AWS CLI commands or Terraform code if applicable
        4. Potential impact of the remediation
        5. Verification steps
        
        Format your response as valid JSON with these exact keys:
        {{
            "risk_assessment": "string",
            "remediation_steps": ["step1", "step2", ...],
            "aws_commands": ["command1", "command2", ...],
            "impact": "string",
            "verification": ["check1", "check2", ...]
        }}
        
        Only respond with the JSON object, no additional text.
        """
    
    def _parse_ai_response(self, analysis: str, vulnerability: Dict) -> Dict:
        """Parse AI response and structure the data"""
        try:
            # Clean the response text
            cleaned_analysis = analysis.strip()
            
            # Remove markdown code blocks if present
            if cleaned_analysis.startswith('```json'):
                cleaned_analysis = cleaned_analysis[7:]
            if cleaned_analysis.endswith('```'):
                cleaned_analysis = cleaned_analysis[:-3]
            cleaned_analysis = cleaned_analysis.strip()
            
            # Try to parse as JSON
            if cleaned_analysis.startswith('{'):
                parsed = json.loads(cleaned_analysis)
                # Validate required fields
                required_fields = ['risk_assessment', 'remediation_steps', 'aws_commands', 'impact', 'verification']
                if all(field in parsed for field in required_fields):
                    return parsed
            
            # If JSON parsing fails, create structured response from text
            return {
                'risk_assessment': f"Security issue identified: {vulnerability.get('title')}",
                'remediation_steps': [
                    'Review AWS security best practices',
                    'Implement least privilege principles',
                    'Monitor AWS Security Hub for recommendations'
                ],
                'aws_commands': [],
                'impact': 'Requires security review',
                'verification': ['Check AWS console for compliance'],
                'raw_analysis': analysis  # Include raw analysis for debugging
            }
            
        except json.JSONDecodeError as e:
            print(f"JSON parsing error: {e}")
            return self._get_fallback_remediation(vulnerability)
        except Exception as e:
            print(f"Analysis parsing error: {e}")
            return self._get_fallback_remediation(vulnerability)
    
    def _get_fallback_remediation(self, vulnerability: Dict) -> Dict:
        """Provide fallback remediation when AI fails"""
        vuln_id = vulnerability.get('id', '')
        
        # Common remediation patterns based on vulnerability type
        if 'SG-OPEN' in vuln_id:
            return {
                'risk_assessment': 'Security group allows unrestricted access from the internet',
                'remediation_steps': [
                    'Identify the security group rules allowing 0.0.0.0/0 access',
                    'Modify security group rules to restrict source IP ranges',
                    'Create a new security group with least privilege principles if needed'
                ],
                'aws_commands': [
                    'aws ec2 describe-security-group-rules --filter Name="group-id",Values="sg-xxxxxxxx"',
                    'aws ec2 revoke-security-group-ingress --group-id sg-xxxxxxxx --protocol tcp --port 22 --cidr 0.0.0.0/0'
                ],
                'impact': 'May temporarily disrupt access if source IPs are not properly configured',
                'verification': [
                    'Verify security group rules in AWS console',
                    'Test connectivity from authorized sources only'
                ]
            }
        elif 'EC2-IMDS-V1' in vuln_id:
            return {
                'risk_assessment': 'Instance Metadata Service v1 is enabled, which is less secure than v2',
                'remediation_steps': [
                    'Modify instance metadata options to require IMDSv2',
                    'Test application compatibility with IMDSv2',
                    'Update any scripts using IMDSv1'
                ],
                'aws_commands': [
                    'aws ec2 modify-instance-metadata-options --instance-id i-xxxxxxxx --http-tokens required --http-endpoint enabled'
                ],
                'impact': 'Applications using IMDSv1 will need to be updated',
                'verification': [
                    'Check instance metadata options in AWS console',
                    'Test metadata access using IMDSv2 tokens'
                ]
            }
        else:
            return {
                'risk_assessment': f"Security issue identified: {vulnerability.get('title')}",
                'remediation_steps': [
                    'Review AWS security documentation for this resource type',
                    'Implement AWS security best practices',
                    'Consult AWS Security Hub for specific recommendations'
                ],
                'aws_commands': [],
                'impact': 'Requires security review and planning',
                'verification': ['Check resource configuration in AWS console']
            }